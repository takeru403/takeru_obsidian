# Accelerating HEC-RAS: A Recurrent Neural Operator for Rapid River Forecasting



Elias Ioup
_Center for Geospatial Sciences_
_Naval Research Laboratory_
Mississippi, USA
elias.z.ioup.civ@us.navy.mil



Maximilian Zoch

_CoDiS-Lab ISDS_

_Graz Technical University of Technology_
Graz, Austria
maximilian.zoch@tugraz.at



Edward Holmberg
_Gulf States Center for Env. Informatics_
_University of New Orleans_
Louisiana, USA

eholmber@uno.edu



Pujan Pokhrel
_Gulf States Center for Env. Informatics_
_University of New Orleans_
Louisiana, USA
ppokhre1@uno.edu



Jay Ratcliff
_Gulf States Center for Env. Informatics_
_University of New Orleans_
Louisiana, USA
jratclif@uno.edu


Mahdi Abdelguerfi
_Gulf States Center for Env. Informatics_
_University of New Orleans_
Louisiana, USA
gulfsceidirector@uno.edu



Kendall Niles

_US Army Corps of Engineers_
_Vicksburg District_
Mississippi, USA
kendall.niles@usace.army.mil


Julian Simeonov

_Ocean Sciences Division_

_Naval Research Laboratory_
Mississippi, USA
julian.a.simeonov.civ@us.navy.mil



Ken Pathak

_US Army Corps of Engineers_
_Vicksburg District_
Mississippi, USA
ken.pathak@usace.army.mil


Maik Flanagin
_US Army Corps of Engineers_
_New Orleans District_

Louisiana, USA
maik.c.flanagin@usace.army.mil



Steven Sloan

_US Army Corps of Engineers_
_Vicksburg District_
Mississippi, USA
steven.sloan@usace.army.mil


Christian Guetl

_CoDiS-Lab ISDS_

_Graz University of Technology_
Graz, Austria
c.guetl@tugraz.at



_**Abstract**_ **—Physics-based solvers like HEC-RAS provide high-**
**fidelity river forecasts but are too computationally intensive**
**for on-the-fly decision-making during flood events. The central**
**challenge is to accelerate these simulations without sacrificing**
**accuracy. This paper introduces a deep learning surrogate that**
**treats HEC-RAS not as a solver but as a data-generation engine.**
**We propose a hybrid, auto-regressive architecture that combines**
**a Gated Recurrent Unit (GRU) to capture short-term temporal**
**dynamics with a Geometry-Aware Fourier Neural Operator (Geo-**
**FNO) to model long-range spatial dependencies along a river**
**reach. The model learns underlying physics implicitly from a**
**minimal eight-channel feature vector encoding dynamic state,**
**static geometry, and boundary forcings extracted directly from**
**native HEC-RAS files. Trained on 67 reaches of the Mississippi**
**River Basin, the surrogate was evaluated on a year-long, unseen**
**hold-out simulation. Results show the model achieves a strong**
**predictive accuracy, with a median absolute stage error of**
**0.31 feet. Critically, for a full 67-reach ensemble forecast, our**
**surrogate reduces the required wall-clock time from 139 minutes**
**to 40 minutes, a speedup of nearly 3.5 times over the traditional**
**solver. The success of this data-driven approach demonstrates**
**that robust feature engineering can produce a viable, high-speed**
**replacement for conventional hydraulic models, improving the**
**computational feasibility of large-scale ensemble flood forecast-**
**ing.**
_**Index Terms**_ **—Fourier Neural Operator, Surrogate Modelling,**
**HEC-RAS, Flood Forecasting, Model Compilation, PyTorch**


I. I NTRODUCTION


**The Urgency of Flood Forecasting.** During a flood, the
U.S. Army Corps of Engineers (USACE) must make critical decisions, from issuing evacuation orders to scheduling
gate operations, within minutes[8]. This operational tempo is
fundamentally at odds with the _O_ (hours) wall-clock times
required by physics-based solvers such as HEC-RAS to
simulate unsteady flow[8], [7]. While pre-computed scenario



libraries or reduced-order models offer one work-around, they
are often too coarse to capture the specific hydrograph that
unfolds in real time[11], [9].


**The Challenge.** The central challenge is to deliver the fidelity
of a HEC-RAS simulation [8] at a speed that enables rapid,
on-the-fly ensemble forecasting, turning hours of computation
into timely insights [8], [7].


**This Paper’s Contribution.** We address this challenge by
reframing the HEC-RAS workflow itself. Instead of relying
on its iterative solver [8], we treat its native project files as a
direct source of training data for a deep-learning surrogate.
We propose an autoregressive _GRU–GeoFNO_ model, that
learns the complex spatio-temporal dynamics of river flow. The
network ingests a minimal eight-channel vector representing
dynamic state, static geometry, and boundary forcings, and
then rolls the simulation forward hour-by-hour.


**Key Innovations:**

1) _A True Plug-in Surrogate:_ Our model requires no remeshing or data conversion, reading the native .g##,
.u##, and DSS file bundle directly.
2) _A Minimalist Universal Interface:_ We identify a compact
eight-channel feature set sufficient for stable, multi-day
forecasts that is common across public 1-D HEC-RAS
projects.
3) _A_ _Hybrid_ _Autoregressive_ _Architecture:_ Our
GRU–GeoFNO loop couples a Gated Recurrent Unit for
short-term memory with a Fourier Neural Operator for
long-range spatial dependencies, maintaining stability
without explicit physics-based loss terms.
Together, these advances elevate autoregressive neural operators from academic prototypes to operationally promising


engines for rapid ensemble flood guidance.


II. B ACKGROUND : HEC-RAS AS A D ATA P REPROCESSOR


_A. HEC-RAS: The Industry-Standard Solver_


HEC-RAS, the U.S. Army Corps of Engineers’ River
Analysis System, is widely regarded as the industry-standard
platform for river hydraulics [8]. Under the hood, it solves the
one-dimensional Saint-Venant equations[7] using an implicit
Newton–Raphson finite-difference scheme, with several inner
iterations per global time step to balance continuity and
momentum [8]. This strategy delivers high numerical accuracy
but at a steep computational cost: full-reach unsteady-flow
simulations typically require hours to days of wall-clock time

[8], [11].


_B. Novel Use Case: From Solver to Pre-Processor_


This work treats HEC-RAS not as an end-to-end simulation

tool, but as a powerful data-generation engine. By leveraging
its mature GIS and project-management capabilities [8], we
can assemble consistent geometries, meshes, and boundary
hydrographs directly from the native project bundle [8], [12],

[25], [26]. We then export this curated file set into a machinelearning pipeline. The surrogate ingests these inputs, learns
the hydraulic relationships and returns reach-scale forecasts
in seconds rather than hours [11]. In this workflow HEC-RAS
becomes a build tool for high-quality training data, while the
surrogate supplies the speed needed for rapid what-if analyses.


_C. The HEC-RAS File Ecosystem_


The key to this approach is the structured, informationrich file bundle that constitutes a standard HEC-RAS project.
These files contain all the static, quasi-static, and dynamic
information required to train a robust surrogate model, as
summarized in Table I.


TABLE I: HEC-RAS file bundle organised by information
type. ‘##‘ denotes version indices.


**Files** **Class** **Key contents**


_Static geometry_


- [.g##] XS/1-D Station–elevation pairs, banks, centre-line
- [.c##] 2-D mesh Cell polygons, bed elevation, roughness zones
- [.b##] 1-D structs Bridge and culvert shapes, pier spacing


_Quasi-static metadata_


- [.p##] Plan Geometry/flow linkage, solver tolerances


_Dynamic time-series_


- [.u##] Unsteady flow Hydrograph pointers, gate schedules, run
window
- [.dss] DSS Upstream _Q_ ( _t_ ), downstream _H_ ( _t_ ), lateral
inflows


_D. Key Hydraulic Terminology_


To interpret the model inputs and outputs, we define the
following core terms:



Reach


A contiguous channel segment between two network break-points (e.g. a confluence or control
structure)[8]. Our model operates on a single reach at
a time, advancing from an _upstream node_ (boundary
inflow _Q_ up ) to a _downstream node_ (boundary stage
_H_ dn ).
Stage ( _H_ )

The water-surface elevation at a cross-section, referenced to a project datum such as NAVD 88[7]. Units:

metres.

Discharge ( _Q_ )

The volumetric flow rate through a cross-section,
defined as positive in the downstream direction[7].
Units: m [3] s _[−]_ [1] .


III. R ELATED W ORK

Our work builds on advances in three key areas: data-driven
hydraulic modeling, autoregressive sequence prediction, and
neural operators for scientific computing.


_A. Data-Driven Surrogates for River Hydraulics_

Early data-driven surrogates for river hydraulics often relied
on feed-forward neural networks or polynomial meta-models
to emulate one or two cross-sections at a time [11]. More
recent studies have scaled to full reaches by coupling convolutional encoders with graph neural networks [10], and physicsinformed neural networks have now been demonstrated for

single-reach stage prediction [24]; yet many approaches remain
restricted to steady-flow conditions or simplified rectangular
channels [11], [9]. In contrast, our study targets the entire
unsteady-flow regime of the Mississippi River model, encompassing 67 distinct reaches and thousands of irregularly
spaced, natural-geometry cross-sections.


_B. Autoregressive Models for Temporal Dynamics_

Autoregressive (AR) models, which forecast the next state
by feeding back their own previous outputs, form the backbone
of classical time-series analysis [20]. The closed-loop structure
is computationally efficient for long-horizon roll-outs, but a
known weakness is _error accumulation_ : small mistakes are

recycled and amplified, ultimately drifting the forecast away
from reality [21].
To mitigate this, modern hydrology has shifted from classical ARMA models to Recurrent Neural Networks (RNNs)
such as Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs) [17], [22]. GRUs use update and reset gates
to regulate information flow, capturing temporal dependencies
while remaining parameter-efficient. When applied to river
networks these RNNs typically predict each gage independently, failing to capture the spatial physics that connect
them [22]. Our work addresses this by embedding a GRU
within a spatial operator, allowing the recurrence to span both
time and space. Furthermore, we anchor the AR loop at every
step with the true boundary hydrographs ( _Q_ up _, H_ dn ), providing
a strong physical constraint that drastically reduces long-term
drift.


_C. Neural Operators for Spatial Dependencies_


To model the spatial physics, we turn to the Fourier Neural
Operator (FNO), which learns mappings between function
spaces via global convolutions in the spectral domain [2]. By
modulating Fourier modes directly, FNOs capture long-range
spatial dependencies with high efficiency and are essentially
discretisation invariant [2], [4]. The Geo-FNO variant extends
this concept to irregular meshes by injecting coordinate information into the spectral block, making it well suited to the nonuniform cross-section spacing found in river models [3]. Previous studies have already employed two-dimensional FNOs
for rapid flood-inundation mapping [23]; here we adopt a onedimensional Geo-FNO specifically tailored to the chain-like
topology of a river reach.


_D. Positioning This Work_


Combining recurrent networks with neural operators is an
emerging and powerful tool for modeling complex spatiotemporal systems [18].
A key aspect of our work is its training methodology. We
show that the network learns the underlying hydraulic behavior
implicitly from the data itself. This is achieved through a
carefully engineered eight-channel feature vector that encodes
the system’s essential physical drivers: the channel geometry
( _z_ bed _, z_ bank ), frictional properties ( _n_ man ), and the mass and energy constraints imposed by boundary hydrographs ( _Q_ up _, H_ dn ).
The success of this approach, using a standard mean-squared
error objective with a smoothness regularizer, demonstrates
that meticulous feature engineering is a powerful and efficient
tool for instilling physical consistency in a data-driven surro
gate.


IV. M ETHODOLOGY


We propose an autoregressive surrogate model that learns
the complex spatio-temporal dynamics of river flow from
HEC-RAS simulation data. Figure 1 illustrates the model’s
architecture and the autoregressive data flow. At each time
step, the model ingests a 12-hour history of the river state and
predicts the stage and discharge for the subsequent hour. This
prediction is then fed back into the input sequence, allowing
the model to be unrolled for long-horizon forecasts. Figure 1
illustrates the model’s architecture and the autoregressive data
flow.


_A. Input Feature Vector_


The model’s success hinges on a 8-channel feature vector
that provides a comprehensive physical snapshot of the river
reach at each time step. For each of the _N_ cross-sections in a
reach, we construct a vector containing:


_•_ **Dynamic State (2 channels):** The instantaneous watersurface elevation ( _H_ ) and discharge ( _Q_ ). These are the
variables the model learns to predict.

_•_ **Static Geometry and Roughness (4 channels):** The
thalweg elevation ( _z_ bed ), bank-top elevation ( _z_ bank ), Manning’s roughness coefficient ( _n_ man ), and a normalized



longitudinal coordinate ( _x_ coord ). These time-invariant features encode the unique hydraulic properties of each
cross-section.


_•_ **Boundary Forcings (2 channels):** The upstream discharge ( _Q_ up ) and downstream stage ( _H_ dn ) for the current
time step. These values are broadcast across all _N_ crosssections, providing a consistent physical constraint that
anchors the simulation and reduces drift.


The complete input for one training sample is a tensor of shape

[ _B, L, N,_ 8], where _B_ is the batch size, _L_ = 12 is the sequence
length in hours, _N_ is the number of cross-sections, and 8 is
the number of feature channels. All features are normalized

to zero mean and unit variance using statistics computed from
the training set only.


_B. Network Architecture: A Recurrent Neural Operator_

|INPUT SEQUENCE X — 12 h history per XS<br>dynamic : H, Q (2 channels)<br>static : zbed, zbank, manning_n, x_coord (4 channels)<br>forcings : Qup, Hdn (2 channels)<br>Total: 8<br>Tensor shape: [B, L = 12, N, 8]|Col2|
|---|---|
|||
|**Linear Encoder**<br>(in_channels = 8 + 1_ −→_hidden = 96)|**Linear Encoder**<br>(in_channels = 8 + 1_ −→_hidden = 96)|
|||
|**GRU** (single layer)<br>• operates along 12-step sequence<br>• hidden size = 96|**GRU** (single layer)<br>• operates along 12-step sequence<br>• hidden size = 96|
|||
|**1-D Geo-FNO over the reach**<br>• Fourier modes: 48<br>• input 96_ →_output 96|**1-D Geo-FNO over the reach**<br>• Fourier modes: 48<br>• input 96_ →_output 96|
|||
|**Linear Decoder**<br>96_ →_2 dynamic heads<br>• ˆ<br>_H_ : next-hour Stage (m)<br>• ˆ<br>_Q_ : next-hour Flow (m3 s_−_1)|**Linear Decoder**<br>96_ →_2 dynamic heads<br>• ˆ<br>_H_ : next-hour Stage (m)<br>• ˆ<br>_Q_ : next-hour Flow (m3 s_−_1)|
|||
|**PREDICTION** ˆ_yt_+1** (shape [B, N, 2])**<br>concatenate with static + forcings for_ t_+1|**PREDICTION** ˆ_yt_+1** (shape [B, N, 2])**<br>concatenate with static + forcings for_ t_+1|
|**PREDICTION** ˆ_yt_+1** (shape [B, N, 2])**<br>concatenate with static + forcings for_ t_+1||



Fig. 1: Autoregressive GRU-GeoFNO surrogate architecture. Vertical arrows share a
common inset; the dashed loop feeds predictions back as inputs for the next step.


The core of our surrogate is a hybrid architecture that
combines a Gated Recurrent Unit (GRU) for learning temporal
patterns with a Geometry-Aware Fourier Neural Operator
(Geo-FNO) for capturing spatial dependencies along the river
reach. The data flows through the network as follows:


1) **Positional Encoder:** The 8-channel input vector is
concatenated with its 1-D spatial coordinate ( _x_ coord ), and


a linear layer lifts this 9-dimensional vector to a 96dimensional hidden representation. This explicit inclusion of the coordinate helps the FNO handle irregularly
spaced cross-sections.
2) **Gated Recurrent Unit (GRU):** A single-layer GRU
with a hidden size of 96 processes the 12-hour sequence
for each cross-section independently. This layer acts as
a temporal feature extractor, summarizing the recent
history into a final hidden state vector.
3) **1-D Geo-FNO Block:** The final hidden state from the
GRU (now a tensor of shape [ _B, N,_ 96]) is passed to
a one-dimensional Geo-FNO. This operator performs
a global convolution in the Fourier domain over the
spatial dimension ( _N_ ), allowing it to model long-range
interactions between all cross-sections simultaneously.
Based on our experiments, we use up to 48 Fourier
modes, adapting to the reach length.
4) **Linear Decoder:** A final linear layer projects the 96dimensional output from the FNO block back down to
the two dynamic variables we aim to predict: the nexthour stage ( _H_ [ˆ] ) and discharge ( _Q_ [ˆ] ).


_C. Training and Inference_


A separate model is trained for each of the 67 river reaches.
The model is optimized using the AdamW optimizer with
a learning rate of 2 _×_ 10 _[−]_ [4] over 60 epochs. We use a
data-driven loss function, which is the Mean Squared Error
(MSE) between the predicted and true values of stage and
discharge for the next hour. There is no explicit physics-based
regularization term in the loss.
During inference, the trained model is deployed in an autoregressive loop. The prediction for hour _t_ +1 is concatenated
with the known static and boundary-forcing features for that
hour and becomes part of the input history for predicting hour
_t_ +2. This process, which mirrors the marching scheme of the
HEC-RAS solver, is repeated for the entire year-long holdout period. To accelerate performance, the model is optimized
with torch.compile.


_D. Rationale for the Fourier Neural Operator Architecture_


The selection of a Fourier Neural Operator (FNO) as the
core of our spatial modeling block is motivated by the inherent
analogy between a one-dimensional river reach and a physical
signal. At any instant in time, the state of the river can be
represented as a 1D function, where the spatial domain is the
distance along the river’s centerline and the function’s value is
a physical quantity like stage ( _H_ ) or discharge ( _Q_ ). Figure 2
provides a visual representation of this concept, illustrating
the water-surface elevation across all cross-sections in a reach.

This profile is effectively a complex, one-dimensional signal
that evolves over time.

The central principle of the FNO is to analyze this signal
not in the spatial domain, but in the frequency domain. By
applying the Fourier Transform, the complex spatial profile is
decomposed into a sum of simple sinusoidal waves of varying



frequencies and amplitudes. These frequency components have
direct physical interpretations in river hydraulics:


_•_ **Low-frequency modes** correspond to large-scale, longwavelength phenomena. These capture the dominant features of the system, such as the overall water-surface
slope, the primary flood wave, or the large-scale backwater curve imposed by a downstream boundary condition.

_•_ **High-frequency modes** represent small-scale, localized
variations. This includes phenomena like minor oscillations from bridge piers, hydraulic jumps, or other
complex, short-wavelength disturbances along the reach.

Instead of learning the intricate patterns of the spatial
profile directly, the FNO learns the much simpler task of
how to evolve the system’s frequency components over time.
The network ingests the spatial signal, transforms it to the
frequency domain via a Fast Fourier Transform (FFT), applies
a learned linear transformation to the frequency modes, and
transforms the result back to the spatial domain with an Inverse
FFT.

This approach offers a decisive advantage over methods
with local receptive fields, such as Convolutional Neural Networks (CNNs). The Fourier Transform is a global operation;
every point in the frequency domain contains information
from the entire spatial signal. This provides the FNO with
an immediate, global view of the river reach, enabling it to
model long-range spatial dependencies in a single step. This is
critical for river hydraulics, where a change at the downstream
boundary can instantaneously influence the water-surface profile far upstream. The successful outcome of this approach is
evident in Figure 3, which shows a high and consistent NashSutcliffe Efficiency (NSE) across nearly every cross-section in
the _Below Muddy Bank_ reach. This demonstrates that the FNO
has effectively learned to predict the evolution of the entire
spatial "signal," from its dominant low-frequency trends to its
localized high-frequency features, resulting in high predictive
skill across the entire river domain.


Fig. 2: An instantaneous stage snapshot across all crosssections in a reach. This water-surface profile can be interpreted as a one-dimensional signal, where the y-axis is stage
and the x-axis is distance along the river.


V. E XPERIMENTAL S ETUP


This section details the data sources, feature construction,
and the protocol used for training and evaluating the surrogate
models.


Fig. 3: Per-cross-section NSE along _Below Muddy Bank_ . The
high skill across the entire spatial domain indicates the FNO’s
effectiveness at learning the global dynamics of the river
"signal."


_A. Study Area and Data Sources_


The study is conducted on the official U.S. Army
Corps of Engineers (USACE) HEC-RAS model
of the Mississippi River Basin, identified as the
“2011_2008_2002_Projects(10_5_2016)” project.
This comprehensive model contains 67 distinct onedimensional river reaches, which form the basis of our
experiments.
Our data is extracted from two primary HDF5 files within
the project:


_•_ **Geometry Data:** Provides static, time-invariant information for each cross-section (XS), including river station
(chainage), bed elevation profiles, bank station locations,
and Manning’s roughness coefficients.

_•_ **Simulation Results:** Contains the hourly time-series output from unsteady flow simulations for three hydrologic
years, each characterized by a major flood event. The
key variables are water-surface elevation (Stage, _H_ ) and
discharge (Flow, _Q_ ).


**Year** **Primary Flood Event** **# Hourly Snapshots**


2002 June–Sept. Moderate Flood 8,737
2008 May 50-Year Flood 8,783
2011 April Historic Flood 8,737


All raw data, originally in imperial units, are converted to SI
units (metres, m³/s) during pre-processing.


_B. Training and Evaluation Protocol_


To ensure a robust test of generalization, we use a strict
temporal splitting strategy for each of the 67 reaches.
**Training & Validation Sets:** Data from the 2002 and 2008
simulations are concatenated to form a single training sequence (approx. 17,520 hourly snapshots per reach). The final
20

**Hold-out Test Set:** The entire 2011 simulation is held out

as a completely unseen test set for the final evaluation of the
trained model.

**Training Procedure:** A separate surrogate model is trained
independently for each of the 67 river reaches. Each model



is trained for 60 epochs using the AdamW optimizer with
a learning rate of 2 _×_ 10 _[−]_ [4] . The objective is a data-driven
Mean Squared Error (MSE) loss between the predicted and
true next-hour stage and discharge.


_C. Autoregressive Rollout_


Final evaluation is performed via an autoregressive rollout
on the 2011 hold-out data, mimicking a real-world forecasting
scenario. The process is as follows:


1) The model is initialized with a 12-hour history of true
data from the beginning of the 2011 simulation.
2) It predicts the state (Stage and Flow) for the next hour
( _t_ + 1).
3) This prediction is then combined with the known
static geometry features and the true boundary forcings
( _Q_ up _, H_ dn ) for hour _t_ + 1.
4) This newly constructed state becomes part of the input
history for predicting the state at hour _t_ + 2.


This iterative process is repeated for the entire year-long forecast horizon (8,725 steps). All experiments were performed
using PyTorch.


VI. E VALUATION M ETRICS


To provide a comprehensive assessment of the surrogate model’s performance, we evaluate its predictions ( _y_ [pred] )
against the HEC-RAS ground truth ( _y_ [true] ) over a time series of
length _T_ . We use a set of complementary metrics, including
direct error measures in physical units and a normalized skill

score.


**Root Mean Square Error (RMSE)** quantifies the typical
magnitude of error in the original units of the variable. By
squaring residuals, it is particularly sensitive to large errors,
such as those that might occur during peak flow events.



**Nash-Sutcliffe Efficiency (NSE)** is a normalized metric that
gauges how well the forecast tracks the observed hydrograph
relative to the observed mean ( _y_ [true] ). An NSE of 1 indicates
a perfect match, while an NSE of 0 indicates the model is no
better than a forecast of the mean.

NSE = 1 _−_ � ~~�~~ _TtTt_ ==11 [(][(] _[y][y]_ _t_ [pred] _t_ [true] _−−_ _yy_ [true] _t_ [true] )) [2][2] (3)



RMSE =



~~�~~
~~�~~
�


_T_

� [1]



_T_


_−_

�( _y_ _t_ [pred] _y_ _t_ [true] ) [2] (1)


_t_ =1



**Mean Absolute Error (MAE)** also measures the average
error magnitude in the original units but is less sensitive to
large outliers than RMSE. It provides an easily interpretable
measure of the average forecast miss.



MAE = [1]

_T_



_T_


_−_

� _|y_ _t_ [pred] _y_ _t_ [true] _|_ (2)


_t_ =1


VII. R ESULTS AND A NALYSIS


The trained surrogate models were evaluated on the unseen
2011 hold-out year via a full-length autoregressive rollout.
This section details the model’s performance, beginning with
a quantitative analysis of its accuracy, followed by qualitative
case studies, a validation of our key design choices through ablation studies, and an assessment of its computational speedup.


_A. Quantitative Performance Analysis_


Across the entire 67-reach ensemble, the surrogate model
demonstrates a strong predictive capability. The distribution of
absolute stage errors for every prediction in the hold-out year
is sharply peaked near zero, with a **median absolute error of**
**only 0.31 feet**, as shown in the error histogram in Figure 5.
The long tail of this distribution, which pulls the mean error
to 1.81 feet, indicates that while most predictions are highly
accurate, performance varies by location.
This variance is detailed in Figure 4, which shows the perreach distribution of absolute stage errors, sorted by median.
A clear pattern emerges: large, well-defined channels like the
‘Mississippi‘ and ‘Ouachita River‘ cluster to the right with
low median errors and tight interquartile ranges. In contrast,
smaller tributaries or hydraulically complex reaches like the
‘Obion River‘ and ‘YazooRiver‘ show higher median errors
and greater variability. The precise median absolute stage error
for all 67 reaches is catalogued in the box-plot figure.


_B. Qualitative Case Studies: Representative Reaches_


To provide a qualitative understanding of the performance
differences identified above, we examine the year-long forecast
hydrographs for several representative reaches.
**Success Case: Major River Channel.** On well-defined conveyance channels, the model shows high fidelity. For example,
on the ‘Mississippi River / Below Vicksburg‘ reach, the
surrogate accurately tracks the HEC-RAS ground truth through
multiple flood waves over the entire 8,725-hour forecast,
capturing both the timing and magnitude of flood crests and
subtle low-flow fluctuations.
**Challenging Cases: Complex Hydraulics.** The model’s limitations become apparent on reaches with more complex
dynamics. Figure 8 shows how the surrogate develops highfrequency oscillations on the ‘Forked Deer / South Fork‘
during low-flow periods, a sign of potential instability when
the hydraulic signal is weak.


_C. Ablation Studies: Validation of Model Design_


To validate our core design choices, we conducted two
targeted ablation studies to isolate the impact of feature
engineering and training data diversity.
_1) Impact of Physics-based Feature Engineering:_ We tested
the hypothesis that encoding static physical properties into
the feature vector is critical for stability. We trained a model
variant on the _Below Muddy Bank_ reach where Manning’s
roughness ( _n_ man ) and bank-top elevation ( _z_ bank ) were removed.
The results in Figure 6 are unequivocal. The ablated model



suffers a tripling of RMSE and develops a prominent lowfrequency bias compared to the full model. This demonstrates
that providing explicit geometric and frictional constraints is
paramount for learning the correct physical relationships.

_2) Impact of Training Data Volume and Diversity:_ A second study investigated the model’s ability to generalize to
the historic 2011 flood, focusing on the _Mississippi / Below_
_Vicksburg_ reach. We compared two models: one trained on
only 80% of the 2002 and 2008 data (with 20% held out for
validation), and another trained on the full 100% of that data.
As shown in Figure 7(a), the model trained on the incomplete dataset fails catastrophically when evaluated on the
unseen 2011 event. It severely underpredicts the flood peak
and develops large oscillations, a clear sign of attempting to
extrapolate far beyond its learned experience.
In contrast, Figure 7(b) shows the performance of the
model trained on the _entirety_ of the 2002 and 2008 data. By
being exposed to the complete hydrologic diversity available
in the training years, this model is far more successful at
generalizing. It accurately tracks the ground truth of the larger,
unseen 2011 flood, demonstrating that the completeness and
diversity of the training corpus are paramount for ensuring the
model is robust enough for extreme events.


_D. Computational Performance_


A primary motivation for surrogate modeling is the reduction of computational cost. We benchmarked the time
required to generate a full 8737-hour (1-year) forecast for all
67 reaches. All timings were performed on the same hardware
for a fair comparison.

The results of this end-to-end evaluation are summarized

in Table II. While the theoretical, per-step inference of the
neural network is orders of magnitude faster than the solver,
the practical wall-clock time for the full ensemble forecast is
the most operationally relevant metric. Our surrogate model
completes this task in just 40 minutes, compared to 139
minutes for the HEC-RAS ensemble, resulting in a 3.45x
speedup.


TABLE II: Inference Time Comparison for a 1-year Forecast.


**Model** **Wall-Clock Time**


HEC-RAS 5.0.1 Simulation 139 minutes
**Recurrent FNO Surrogate** 40 minutes


**Speedup Factor** 3 _._ 45


_E. Tabular and Visual Results_


To validate our core design choices, we conducted two
targeted ablation studies. The first investigates the impact of
our physics-based feature engineering on model stability. The
second examines the model’s sensitivity to the volume and
diversity of training data, particularly its ability to generalize

to extreme events.


Fig. 4: Per-reach distribution of absolute stage error (2011 hold-out), sorted by median. Large channels cluster at the right with low error; hydraulically complex tributaries
appear on the left.



Fig. 5: Absolute-stage–error histogram for all time steps across
the 67 reaches in the 2011 hold-out year. The long tail explains
why the mean (1.8 ft) greatly exceeds the median (0.31 ft).


_1) Impact of Physics-based Feature Engineering:_ We tested
the hypothesis that encoding static physical properties directly
into the feature vector is critical for model stability and



accuracy. To do this, we trained a variant of the model on
the _Below Muddy Bank_ reach where two key static channels,
Manning’s roughness coefficient ( _n_ man ) and bank-top elevation
( _z_ bank ), were removed from the input vector, leaving only
dynamic state and boundary conditions.
The results, shown in Figure 6, are unequivocal. The full
model, with all eight feature channels, accurately tracks the
ground-truth stage (Fig. 6a). In contrast, the ablated model
exhibits severe performance degradation (Fig. 6b). The Root
Mean Square Error (RMSE) triples, and the forecast develops
a low-frequency bias, failing to capture the correct hydraulic
behavior. This demonstrates that providing the model with
explicit geometric and frictional constraints is paramount;
without them, the model cannot implicitly learn the correct
physical relationships from the time-series data alone.
_2) Impact of Training Data Volume and Diversity:_ A second study investigated the model’s ability to generalize to
extreme events not seen during training. We focused on the
_Mississippi / Below Vicksburg_ reach, which experienced a
historic flood in the 2011 hold-out year that was larger in
magnitude than the events in the initial training set (the 2002


(a) Stage forecast without _z_ bank & _n_ man (b) Stage forecast with full features


Fig. 6: Feature ablation impact on stage prediction for the _Below Muddy Bank_ reach. The ablated model (a), which lacks
roughness and bank-height features, develops bias and error. In contrast, the full model (b) accurately tracks the ground truth.
Removing these static channels triples the stage RMSE.


(a) Training on 2002+2008 with 80%train set / 20% validation (b) 100% train on 2002+2008 and Q1 2011 for validation


Fig. 7: Data-volume ablation on _Mississippi / Below Vicksburg_



and 2008 simulations).


As shown in Figure 7a, the model trained only on the 2002
and 2008 data fails catastrophically during the 2011 rollout. It
severely underpredicts the peak stage of the flood and develops
large oscillations, a clear sign of attempting to extrapolate far
beyond its learned experience.


We then retrained the model, augmenting the training set by
including the first quarter of the 2011 simulation (an increase
of 8,737 hourly snapshots). This modest increase in data
volume provided a crucial increase in hydrologic diversity by
exposing the model to the rising limb of the major flood. The
impact was transformative. As seen in Figure 7b, the retrained
model now accurately tracks the ground truth for the remainder



of the year, halving the peak-stage error and eliminating the
instability. This confirms that the model is "data-hungry," not
just for more observations, but for more diverse observations.
To be operationally reliable, a surrogate must be trained on a
data set that encompasses the full range of expected hydrologic
conditions, especially rare, high-impact events.“‘


VIII. D ISCUSSION

The results confirm that our autoregressive surrogate, when
built upon a robust data pipeline, can successfully emulate
HEC-RAS simulations. However, the path to this success
reveals two primary principles for developing viable datadriven hydraulic models: first, that physically-grounded feature
engineering is paramount for stability, and second, that the


Fig. 8: Instability during a low-flow period on the _Forked Deer_
_/ South Fork_ . The high-frequency oscillations are characteristic
of the model operating in a data-sparse regime. This parallels
the data-volume ablation study (cf. Figure 7), suggesting that
the model’s performance could be substantially improved by
augmenting the training set with more observations of lowflow conditions.


model’s ability to generalize to extreme, unseen events is
fundamentally dependent on the completeness and diversity
of its training data. This section discusses these principles and
their resulting constraints on the model’s current operational

scope.


_A. The Primacy of Physics-Aware Features over Model Com-_
_plexity_


The most critical lesson from this work is that **intelligent**
**feature engineering trumps model or loss function com-**
**plexity.** Our initial experiments, which used only dynamic
state inputs, produced forecasts that were numerically unstable. The breakthrough was not a more complex loss function,
but rather enriching the feature vector with static hydraulic
channels ( _z_ bed, _z_ bank, _n_ man, _x_ coord ) and boundary forcings ( _Q_ up,
_H_ dn ). As demonstrated in the ‘Results‘ section, this refinement
alone eliminated systematic bias and instability, transforming
the model from an unreliable prototype into a robust surrogate.
The model learns precisely the physics we encode in its inputs.


_B. The Fragility of Extrapolation and the Value of Training_
_Data Completeness_


While robust feature engineering ensures stability, the
model’s ability to generalize to events outside its training
distribution is a primary operational concern. This is starkly
illustrated by the data-volume ablation study on the _Mississippi_
_/ Below Vicksburg_ reach, where the model’s performance on
the unseen 2011 historic flood was evaluated under different
training conditions.
Figure 7a shows the model’s performance when trained on
only a portion of the 2002 and 2008 data (with the remainder
used for internal validation). In this configuration, the model
fails catastrophically when confronted with the 2011 flood,
severely underpredicting the flood peak and developing large
instabilities.



In contrast, Figure 7b shows the performance of a model
trained on the _entirety_ of the 2002 and 2008 data. This model,
having been exposed to the complete hydrologic diversity
available, including the major 50-year flood in 2008, is far
more successful at generalizing to the unprecedented 2011
event, tracking the hydrograph with reasonable accuracy.
This finding is crucial: **the model’s ability to extrapolate**
**is fragile and highly sensitive to the completeness of**
**its training set.** It demonstrates that while the model _can_
generalize from one major flood to a larger, unseen one,
its reliability is contingent on being trained on the most
diverse and comprehensive dataset possible. The catastrophic
failure in the first scenario highlights a critical operational
risk: even a standard practice like holding out a validation set
from the training data can degrade the model’s robustness to
extreme events. This sensitivity underscores a key constraint
for deployment and emphasizes the need for careful curation
of training corpora to maximize hydrologic diversity.


_C. Operational Constraints in Complex Hydraulic Regimes_


Beyond extrapolation, the model’s performance on reaches
with complex hydraulics, such as those with low-flow, reverseflow, or backwater effects, presents another constraint on its
current operational scope. As shown in the qualitative analysis
of the _Forked Deer / South Fork_ reach, the surrogate can
develop high-frequency instabilities in data-sparse, low-flow
regimes. Furthermore, its struggles on reaches like _Bayou_
_Bourdeaux_ indicate difficulty in capturing the dynamics of
backwater-affected areas.

Since any comprehensive, basin-scale forecast must account
for the interconnectedness of primary river channels and their
more complex tributaries, this currently limits the surrogate’s
applicability to well-defined, primary conveyance channels
where flow is consistently unidirectional and well-gauged.
Addressing these complex behaviors is a primary driver for
the future work outlined in this paper.


IX. C ONCLUSION


This work addresses the critical need for rapid, high-fidelity
flood forecasting by developing a deep learning surrogate
for the computationally expensive HEC-RAS solver. We have
demonstrated that a hybrid autoregressive architecture, combining a Gated Recurrent Unit for temporal memory and a
Geometry-Aware Fourier Neural Operator for spatial dependencies, can successfully emulate year-long unsteady flow
simulations with remarkable accuracy.
Our key finding is that the success of such a surrogate is
contingent not only on the neural architecture but, critically,
on a meticulously engineered, physically consistent feature
set. By sourcing static features like channel geometry and
roughness directly from the HEC-RAS project files, our purely
data-driven model learns the underlying physics implicitly.
This approach achieves stable, accurate forecasts and, for a
full 67-reach ensemble, reduces the required wall-clock time
from 139 minutes to 40 minutes, a speedup of nearly 3.5 times.


This work therefore represents a step forward in elevating
the GRU-GeoFNO model from an academic prototype towards
an operational tool. However, its current viability is scoped to
well-defined river channels and constrained by **its sensitivity**
**to out-of-distribution events and its struggles in hydrauli-**
**cally complex tributaries**, highlighting the need for continued
research before widespread deployment.


_A. Future Work_


The limitations identified in our analysis, namely **the**
**model’s fragility when extrapolating and its struggles in**
**backwater-affected zones**, define a clear trajectory for future
research. The primary focus will be on extending the model’s
capabilities from isolated reaches to full, interconnected river
networks. This involves two main avenues of exploration:


1) **Topological Awareness with Graph Neural Opera-**
**tors:** The model’s failure in backwater-affected zones

highlights the need for it to understand network topology. The most promising next step is to employ **Graph**
**Neural Operators (GNOs)** [16], a class of models
designed to learn mappings between function spaces
defined on graphs. This is a natural extension of our current FNO-based approach and, unlike traditional GNNs,
a GNO is discretization-invariant. This would allow

a surrogate trained on one network representation to
be applied to a more refined one without retraining,
enabling the model to learn the network-scale physics
required to resolve complex phenomena like backwater
effects at confluences.
2) **Enriching the Feature Set:** To improve performance in
more complex scenarios, we will incorporate additional
time-dependent operational inputs that are available in
HEC-RAS but were omitted from this study. These
include gate operation schedules, pump station activity,
and reservoir release rule curves, which act as critical
internal boundary conditions within the river system.

By addressing these areas, we aim to develop a holistic,
network-aware surrogate capable of providing rapid, basinscale flood forecasting in complex and mission-critical scenarios..


R EFERENCES


[1] M. Raissi, P. Perdikaris, and G. E. Karniadakis, “Physics-informed
neural networks: A deep learning framework for solving forward and
inverse problems involving nonlinear partial differential equations,”
_Journal of Computational Physics_, vol. 378, pp. 686–707, 2019.

[2] Z. Li, N. Kovachki, K. Azizzadenesheli, B. Liu, K. Bhattacharya,
A. Stuart, and A. Anandkumar, “Fourier neural operator for parametric
partial differential equations,” in _Proc. ICLR_, 2021.

[3] Z. Li, D. Z. Huang, B. Liu, and A. Anandkumar, “Fourier neural
operator with learned deformations for PDEs on general geometries,”
_arXiv preprint arXiv:2207.05209_, 2022.

[4] N. Rahaman, A. Baratin, D. Arpit, F. Draxler, M. Lin, F. Hamprecht,
Y. Bengio, and A. Courville, “On the spectral bias of neural networks,”
in _Proc. 36th Int. Conf. Machine Learning (ICML)_, vol. 97, pp. 5301–
5310, 2019.

[5] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for
image recognition,” in _Proc. IEEE Conf. Computer Vision and Pattern_
_Recognition (CVPR)_, 2015, pp. 770–778.




[6] M. Zoch, E. Holmberg, P. Pokhrel, K. Pathak, S. Sloan, K. Niles,
J. Ratcliff, M. Flanagin, E. Ioup, C. Guetl, and M. Abdelguerfi, “Physicsinformed neural network surrogate models for river stage prediction,”
_arXiv preprint arXiv:2503.16850_, 2025.

[7] H. Chanson, _Hydraulics_ _of_ _Open_ _Channel_ _Flow_ . ButterworthHeinemann, 2004.

[8] G. W. Brunner, “HEC-RAS river analysis system, hydraulic reference
manual,” U.S. Army Corps of Engineers, Hydrologic Engineering Center, Davis, CA, Tech. Rep. CPD-69, 2021.

[9] P. Benner, S. Gugercin, and K. Willcox, “A survey of projection-based
model reduction methods for parametric dynamical systems,” _SIAM_
_Review_, vol. 57, no. 4, pp. 483–531, 2015.

[10] H. Bi, J. Lin, and X. Zhao, “Data-driven surrogate modeling in computational fluid dynamics: A review,” _Computers and Fluids_, vol. 258,
p. 104764, 2023.

[11] Z. Takbiri-Borujeni, J. T. Smith, and M. D. White, “Challenges of
using surrogate models for environmental simulations: A case study in
hydrology,” _Environmental Modelling and Software_, vol. 134, p. 104882,
2020.

[12] M. Flanagin, A. Grenotton, J. Ratcliff, K. B. Shaw, J. Sample, and
M. Abdelguerfi, “Hydraulic splines: A hybrid approach to modeling river
channel geometries,” _Computing in Science and Engineering_, vol. 9,
no. 5, pp. 4–15, 2007.

[13] C. R. Qi, H. Su, K. Mo, and L. J. Guibas, “PointNet: Deep learning on
point sets for 3D classification and segmentation,” in _Proc. IEEE Conf._
_Computer Vision and Pattern Recognition (CVPR)_, 2017, pp. 652–660.

[14] M. Abdelguerfi, _3D Synthetic Environment Reconstruction_ . Springer,
2012.

[15] M. Chung, R. Wilson, R. Ladner, T. Lovitt, M. Cobb, M. Abdelguerfi,
and K. Shaw, “The geospatial information distribution system (GIDS),”
in _Succeeding with Object Databases_ . John Wiley & Sons, 2001,
pp. 357–378.

[16] Z. Li, N. Kovachki, K. Azizzadenesheli, B. Liu, K. Bhattacharya,
A. Stuart, and A. Anandkumar, “Graph neural operator for PDEs,” _arXiv_
_preprint arXiv:2010.08895_, 2020.

[17] K. Cho, B. van Merriënboer, C. Gülçehre, D. Bahdanau, F. Bougares,
H. Schwenk, and Y. Bengio, “Learning phrase representations using
RNN Encoder–Decoder for statistical machine translation,” in _Proc._
_Empirical Methods in Natural Language Processing (EMNLP)_, Doha,
Qatar, 2014, pp. 1724–1734.

[18] J. Brandstetter, D. E. Worrall, and M. Welling, “Message passing neural
PDE solvers,” in _Proc. Int. Conf. on Learning Representations (ICLR)_,
[2022. [Online]. Available: https://arxiv.org/abs/2202.03376](https://arxiv.org/abs/2202.03376)

[19] J. Pathak, S. Subramanian, P. Harrington, S. Raja, A. Chattopadhyay,
M. Mardani, T. Kurth, D. Hall, Z. Li, K. Azizzadenesheli, P. Hassanzadeh, K. Kashinath, and A. Anandkumar, “FourCastNet: A global
data-driven high-resolution weather model using adaptive Fourier neural
operators,” in _Advances in Neural Information Processing Systems_
_(NeurIPS)_ [, 2022. [Online]. Available: https://arxiv.org/abs/2202.11214](https://arxiv.org/abs/2202.11214)

[20] G. E. P. Box and G. M. Jenkins, _Time Series Analysis: Forecasting and_
_Control_ . San Francisco, CA: Holden–Day, 1970.

[21] S. Bengio, O. Vinyals, N. Jaitly, and N. Shazeer, “Scheduled sampling
for sequence prediction with recurrent neural networks,” in _Advances in_
_Neural Information Processing Systems (NeurIPS)_, vol. 28, Montréal,
Canada, 2015, pp. 1171–1179.

[22] F. Kratzert, D. Klotz, J. Herrnegger, G. Hochreiter, and S. Nearing,
“Toward improved predictions in ungauged basins: Exploiting the power
of machine learning,” _Water Resources Research_, vol. 55, no. 12,
pp. 11 344–11 364, 2019.

[23] A. Stenta, J. Smith, and L. Hennig, “FloodFNO: Fourier neural operators
for real-time inundation mapping,” in _Proc. IAHR World Congress_, 2023.

[24] M. Zoch, E. Holmberg, P. Pokhrel, K. Pathak, S. Sloan, K. Niles,
J. Ratcliff, M. Flanagin, E. Ioup, C. Guetl, and M. Abdelguerfi, “Physicsinformed neural network surrogate models for river stage prediction,” in
_Proc. ALLDATA 2025 – 11th Int. Conf. on Big Data, Small Data, Linked_
_Data and Open Data_, 2025.

[25] R. Wilson, M. Cobb, F. McCreedy, R. Ladner, D. Olivier, T. Lovitt,
K. Shaw, F. Petry, and M. Abdelguerfi, “Geographical data interchange
using XML-enabled technology within the GIDB system,” in _XML_
_Data Management: Native XML and XML-Enabled Database Systems_ .
Morgan Kaufmann, 2003, pp. 235–261.

[26] M. Abdelguerfi (ed.), _3D_ _Synthetic_ _Environment_ _Reconstruction_ .
Springer, 2001, vol. 611 of the NATO Science Series.


